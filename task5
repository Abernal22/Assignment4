import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score
import pickle
import time
from fnn import FNN
import numpy as np
from scipy.stats import mode

#Load data
with open('data.pkl', 'rb') as f:
    X_train, X_test, y_train, y_test = pickle.load(f)

X_train_tensor = torch.FloatTensor(X_train.toarray())
X_test_tensor = torch.FloatTensor(X_test.toarray())
y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)
y_test_tensor = torch.FloatTensor(y_test).unsqueeze(1)

#train FNN with drop out.
model = FNN(input_size=10000, hidden_sizes=[512, 256, 128], dropout_rate=0.5)
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

start = time.time()
for epoch in range(10):
    model.train()
    optimizer.zero_grad()
    output = model(X_train_tensor)
    loss = criterion(output, y_train_tensor)
    loss.backward()
    optimizer.step()
end = time.time()

# Evaluate
model.eval()
with torch.no_grad():
    preds = (model(X_test_tensor) > 0.5).float()
    accuracy = (preds == y_test_tensor).float().mean().item()

print(f"FNN dropout Accuracy: {accuracy*100:.2f}%, Time: {end - start:.2f}s")


model = FNN(input_size=10000, hidden_sizes=[512, 256, 128])
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

start = time.time()
for epoch in range(10):
    model.train()
    optimizer.zero_grad()
    output = model(X_train_tensor)
    loss = criterion(output, y_train_tensor)
    loss.backward()
    optimizer.step()
end = time.time()

# Evaluate
model.eval()
with torch.no_grad():
    preds = (model(X_test_tensor) > 0.5).float()
    accuracy = (preds == y_test_tensor).float().mean().item()

print(f"FNN Accuracy: {accuracy*100:.2f}%, Time: {end - start:.2f}s")


#Bagging models.
m = 10
models = []
times = []
preds = []
accuracies = []

#Random data sets for bagging
num = X_train_tensor.size(0)
for i in range(m):
    model = FNN(input_size=10000, hidden_sizes=[512, 256, 128], dropout_rate=0.5)
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    indices = torch.randint(0, num, (num,))
    newTrainx = X_train_tensor[indices]
    newTrainy = y_train_tensor[indices]

    start = time.time()
    for epoch in range(10):
        model.train()
        optimizer.zero_grad()
        output = model(newTrainx)
        loss = criterion(output, newTrainy)
        loss.backward()
        optimizer.step()
    end = time.time()
    model.eval()
    with torch.no_grad():
        pred = (model(X_test_tensor) > 0.5).float()
        accuracy = (pred == y_test_tensor).float().mean().item()
        preds.append(pred)
        accuracies.append(accuracy)
    models.append(model)
    times.append(end-start)


#Majority vote output
majorityResults = mode(preds, axis = 0).mode[:]
accuracy = (majorityResults == y_test_tensor).float().mean().item()
print(f"FNN dropout ensamble Accuracy: {accuracy*100:.2f}%, Time: {sum(times):.2f}s")

    


